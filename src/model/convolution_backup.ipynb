{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c456346-58e7-4ca5-a7d1-c73f632c57f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rs/PycharmProjects/snake-multi/.venv/bin/python3.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cfda99-da70-4d22-9e62-e1b9855ef5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rs/PycharmProjects/snake-multi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35b3e03-0061-4f07-8b59-9c2de566d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:06.658076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756925166.669360   99096 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756925166.672889   99096 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756925166.682903   99096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925166.682915   99096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925166.682917   99096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756925166.682919   99096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-03 20:46:06.686114: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import logging\n",
    "import sys\n",
    "from collections import deque\n",
    "from functools import partial\n",
    "from math import floor, ceil\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.simulation.simulation import Simulation, Vector2\n",
    "from src.simulation.board_generator import make_simple_board\n",
    "\n",
    "from src.model.model_utils import get_model_moves, get_model_scores, get_rotated_state\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices(\"GPU\")[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daccee82-833b-40cb-8d92-59b8082d83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_range = 7\n",
    "replay_buffer_size = 50_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dceffbf-b19a-4665-a9d2-6327d543543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(ate_food: bool, died: bool):\n",
    "    if died:\n",
    "        return -10\n",
    "\n",
    "    if ate_food:\n",
    "        return 10\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d9ac60-7d20-4d5a-942f-419d212c1569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756925168.438366   99096 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1574 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 6), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoding = tf.keras.layers.CategoryEncoding(num_tokens=6, output_mode=\"one_hot\")\n",
    "\n",
    "cat_encoding([[3, 2, 1, 5], [5, 3, 1, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9d561b-3043-4e7d-bc05-769d54539a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#online_model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.Input((view_range * 2 + 1, view_range * 2 + 1)),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.CategoryEncoding(num_tokens=6, output_mode=\"one_hot\"),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(42, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "#    tf.keras.layers.Dense(42, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "#    tf.keras.layers.Dense(1)\n",
    "#])\n",
    "\n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "online_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((view_range * 2 + 1, view_range * 2 + 1)),\n",
    "    tf.keras.layers.CategoryEncoding(num_tokens=7, output_mode=\"one_hot\"),\n",
    "    DefaultConv2D(filters=32, kernel_size=7),\n",
    "    DefaultConv2D(filters=64, kernel_size=5),\n",
    "    DefaultConv2D(filters=64, kernel_size=3),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "target_model = tf.keras.models.clone_model(online_model)\n",
    "target_model.set_weights(online_model.get_weights())\n",
    "\n",
    "view_type = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f37444-ca0a-43b1-8140-8760e68b8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ba69ff-e773-44fc-9059-1cf8588877d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "log_formatter = logging.Formatter(\"%(message)s\")\n",
    "\n",
    "std_handler = logging.StreamHandler(sys.stdout)\n",
    "std_handler.setLevel(logging.INFO)\n",
    "std_handler.setFormatter(log_formatter)\n",
    "\n",
    "file_handler = logging.FileHandler(f\"logs_{model_name}.log\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(log_formatter)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers.clear()\n",
    "logger.addHandler(std_handler)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3400b2a-7e2c-4ed1-a01e-4007cdecb3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ category_encoding_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CategoryEncoding</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ category_encoding_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mCategoryEncoding\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,617</span> (436.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,617\u001b[0m (436.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,617</span> (436.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,617\u001b[0m (436.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff23521-cc83-4c53-9121-701a914b7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756925169.048954   99163 service.cc:152] XLA service 0x7f0b040047d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756925169.048971   99163 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 3GB, Compute Capability 6.1\n",
      "2025-09-03 20:46:09.055482: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1756925169.080317   99163 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-09-03 20:46:09.264972: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[1,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,15,15]{3,2,1,0} %bitcast.302, f32[32,32,5,5]{3,2,1,0} %bitcast.309, f32[32]{0} %bitcast.311), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:09.345693: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[1,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,7,7]{3,2,1,0} %bitcast.318, f32[64,32,3,3]{3,2,1,0} %bitcast.325, f32[64]{0} %bitcast.327), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:09.356645: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[1,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,7,7]{3,2,1,0} %bitcast.332, f32[64,64,3,3]{3,2,1,0} %bitcast.339, f32[64]{0} %bitcast.341), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756925169.578140   99163 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.215972]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation = Simulation(calculate_score)\n",
    "simulation.reset(make_simple_board(np.array([view_range * 2 + 1, view_range * 2 + 1])), 2, 1)\n",
    "\n",
    "online_model.predict(np.array([simulation.get_snake_view(0, view_type, view_range)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d10c28-6166-453f-af12-fc5e93fc8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(snakes_states: list[np.ndarray], snakes_possible_moves: list[list[Vector2]], snakes_alive: list[bool], epsilon: float=0.):\n",
    "    n_snakes = len(snakes_states)\n",
    "\n",
    "    process_mask = [True for _ in range(n_snakes)]\n",
    "    \n",
    "    for i, alive in enumerate(snakes_alive):\n",
    "        if not alive or np.random.rand() < epsilon:\n",
    "            process_mask[i] = False\n",
    "\n",
    "    moves = get_model_moves(online_model, snakes_states, snakes_possible_moves, process_mask, softmax=True)\n",
    "\n",
    "    for i, move in enumerate(moves):\n",
    "        if move == (0, 0):\n",
    "            moves[i] = random.choice(simulation.get_legal_moves(i))\n",
    "\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba36556-fc62-479d-9eb5-393838e68cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        priority_size: int,\n",
    "        normal_size: int,\n",
    "        default_split: float = 0.2,\n",
    "        default_batch_size: int = 32,\n",
    "        threshold_decay: float = 0.3,\n",
    "        threshold_multiplier: float = 1.3\n",
    "    ):\n",
    "        self.priority_buffer = deque(maxlen=priority_size)\n",
    "        self.normal_buffer = deque(maxlen=normal_size)\n",
    "\n",
    "        self.default_split = default_split\n",
    "\n",
    "        self.loss_threshold = 0\n",
    "        self.threshold_decay = threshold_decay\n",
    "        self.threshold_multiplier = threshold_multiplier\n",
    "\n",
    "        self.last_priority_idxs = []\n",
    "        self.last_normal_idxs = []\n",
    "\n",
    "    def append(self, experience: tuple):\n",
    "        self.normal_buffer.append(experience)\n",
    "\n",
    "    def sample(self, split: float = -1, batch_size: int = -1):\n",
    "        if split < 1:\n",
    "            split = self.default_split\n",
    "\n",
    "        if batch_size < 1:\n",
    "            batch_size = self.default_batch_size\n",
    "\n",
    "        if len(self.priority_buffer) < batch_size * split:\n",
    "            split = 0\n",
    "\n",
    "        n_priority = ceil(split * batch_size)\n",
    "        n_normal = floor((1 - split) * batch_size)\n",
    "\n",
    "        batch = []\n",
    "\n",
    "        if n_priority:\n",
    "            idxs = np.random.randint(len(self.priority_buffer), size=n_priority)\n",
    "            batch += [self.priority_buffer[i] for i in idxs]\n",
    "            self.last_priority_idxs = idxs\n",
    "        else:\n",
    "            self.last_priority_idxs = []\n",
    "\n",
    "        if n_normal:\n",
    "            idxs = np.random.randint(len(self.normal_buffer), size=n_normal)\n",
    "            batch += [self.normal_buffer[i] for i in idxs]\n",
    "            self.last_normal_idxs = idxs\n",
    "        else:\n",
    "            self.last_normal_idxs = []\n",
    "            \n",
    "        return [\n",
    "            [experience[field_idx] for experience in batch]\n",
    "            for field_idx in range(6)\n",
    "        ]\n",
    "\n",
    "    def update_loss(self, losses: tf.Tensor, mean_loss: tf.Tensor):\n",
    "        self.loss_threshold *= 1 - self.threshold_decay\n",
    "        self.loss_threshold += self.threshold_decay * mean_loss\n",
    "\n",
    "        for i, priority_idx in enumerate(self.last_priority_idxs):\n",
    "            if losses[i] < self.loss_threshold * self.threshold_multiplier:\n",
    "                if priority_idx != -1:\n",
    "                    del self.priority_buffer[priority_idx]\n",
    "\n",
    "                self.last_priority_idxs[self.last_priority_idxs == priority_idx] = -1\n",
    "                self.last_priority_idxs[self.last_priority_idxs > priority_idx] -= 1\n",
    "\n",
    "        for i, normal_idx in enumerate(self.last_normal_idxs, start=len(self.last_priority_idxs)):\n",
    "            if losses[i] > self.loss_threshold * self.threshold_multiplier:\n",
    "                self.priority_buffer.append(self.normal_buffer[normal_idx])\n",
    "\n",
    "        logger.info(f\"\\tPriority: {len(self.priority_buffer)}\")\n",
    "\n",
    "    def clear(self):\n",
    "        self.priority_buffer.clear()\n",
    "        self.normal_buffer.clear()\n",
    "\n",
    "        self.loss_threshold = 0\n",
    "\n",
    "        self.last_normal_idxs = []\n",
    "        self.last_priority_idxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "560f3b77-eff6-4a8c-b23e-019788dd25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#priority_replay_buffer = deque(maxlen=replay_buffer_size // 2)\n",
    "#replay_buffer = deque(maxlen=replay_buffer_size // 2)\n",
    "\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size // 2, replay_buffer_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680203fa-c1f0-49ee-ac99-f325b3bed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(simulation: Simulation, states_before: list[np.ndarray], possible_moves_before: list[Vector2], snakes_alive_before: list[bool], epsilon: float):\n",
    "    # Save states\n",
    "    moves = epsilon_greedy(states_before, possible_moves_before, snakes_alive_before, epsilon)\n",
    "\n",
    "    scores, running = simulation.next(moves)\n",
    "\n",
    "    states_after = [simulation.get_snake_view(i, view_type, view_range) for i in range(simulation.n_snakes)]\n",
    "    possible_moves_after = [simulation.get_legal_moves(i) for i in range(simulation.n_snakes)]\n",
    "    snakes_alive_after = simulation.snakes_alive\n",
    "\n",
    "    for i in range(len(states_before)):\n",
    "        if snakes_alive_before[i]:\n",
    "            replay_buffer.append((states_before[i], moves[i], scores[i], states_after[i], possible_moves_after[i], snakes_alive_after[i]))\n",
    "\n",
    "    return states_after, possible_moves_after, snakes_alive_after, scores, running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cb2f51b-7b10-487f-871e-6db93422d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_experiences(batch_size: int):\n",
    "    idxs = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    \n",
    "    batch = [replay_buffer[idx] for idx in idxs]\n",
    "\n",
    "    return [\n",
    "        [experience[field_idx] for experience in batch]\n",
    "        for field_idx in range(6)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40a5371d-b644-46db-ba3c-ddf141903eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "discount_factor = 0.9\n",
    "loss_fn = tf.keras.losses.mse\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "\n",
    "def training_step(buffer_split: float):\n",
    "    #experiences = sample_experiences(batch_size)\n",
    "    experiences = replay_buffer.sample(split=buffer_split, batch_size=batch_size)\n",
    "    states, moves, scores, states_after, possible_moves_after, snakes_alive_after = experiences\n",
    "\n",
    "    best_next_moves = [[move] for move in get_model_moves(online_model, states_after, possible_moves_after, snakes_alive_after)]\n",
    "    next_q_values = get_model_scores(target_model, states_after, best_next_moves, snakes_alive_after)\n",
    "    \n",
    "    #next_q_values = get_model_scores(target_model, states_after, possible_moves_after, snakes_alive_after)\n",
    "    runs = 1.0 - np.array(snakes_alive_after)\n",
    "    \n",
    "    target_q_values = scores + runs * discount_factor * next_q_values\n",
    "\n",
    "    X = tf.constant([get_rotated_state(state, move) for state, move in zip(states, moves)])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_q_values = online_model(X)\n",
    "        individual_losses = loss_fn(target_q_values, predicted_q_values)\n",
    "        loss = tf.reduce_mean(individual_losses)\n",
    "\n",
    "    replay_buffer.update_loss(individual_losses, loss)\n",
    "\n",
    "    losses.append(loss.numpy())\n",
    "    grads = tape.gradient(loss, online_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, online_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b34dd6a-b936-4ab2-832f-325145024853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 played\n",
      "\tSteps: 20\n",
      "\tRewards: -10\n",
      "Episode 1 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 2 played\n",
      "\tSteps: 31\n",
      "\tRewards: 0\n",
      "Episode 3 played\n",
      "\tSteps: 7\n",
      "\tRewards: -10\n",
      "Episode 4 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 5 played\n",
      "\tSteps: 40\n",
      "\tRewards: 0\n",
      "Episode 6 played\n",
      "\tSteps: 22\n",
      "\tRewards: -10\n",
      "Episode 7 played\n",
      "\tSteps: 51\n",
      "\tRewards: -10\n",
      "Episode 8 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "Episode 9 played\n",
      "\tSteps: 72\n",
      "\tRewards: 0\n",
      "Episode 10 played\n",
      "\tSteps: 11\n",
      "\tRewards: -10\n",
      "Episode 11 played\n",
      "\tSteps: 43\n",
      "\tRewards: -10\n",
      "Episode 12 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 13 played\n",
      "\tSteps: 84\n",
      "\tRewards: -10\n",
      "Episode 14 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 15 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 16 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 17 played\n",
      "\tSteps: 34\n",
      "\tRewards: -10\n",
      "Episode 18 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 19 played\n",
      "\tSteps: 8\n",
      "\tRewards: -10\n",
      "Episode 20 played\n",
      "\tSteps: 18\n",
      "\tRewards: -10\n",
      "Episode 21 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 22 played\n",
      "\tSteps: 36\n",
      "\tRewards: -10\n",
      "Episode 23 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 24 played\n",
      "\tSteps: 35\n",
      "\tRewards: -10\n",
      "Episode 25 played\n",
      "\tSteps: 11\n",
      "\tRewards: -10\n",
      "Episode 26 played\n",
      "\tSteps: 11\n",
      "\tRewards: -10\n",
      "Episode 27 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 28 played\n",
      "\tSteps: 7\n",
      "\tRewards: -10\n",
      "Episode 29 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 30 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 31 played\n",
      "\tSteps: 27\n",
      "\tRewards: -10\n",
      "Episode 32 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 33 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 34 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 35 played\n",
      "\tSteps: 27\n",
      "\tRewards: 0\n",
      "Episode 36 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 37 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 38 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 39 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 40 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 41 played\n",
      "\tSteps: 25\n",
      "\tRewards: -10\n",
      "Episode 42 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 43 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 44 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 45 played\n",
      "\tSteps: 17\n",
      "\tRewards: -10\n",
      "Episode 46 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 47 played\n",
      "\tSteps: 30\n",
      "\tRewards: -10\n",
      "Episode 48 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 49 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 50 played\n",
      "\tSteps: 20\n",
      "\tRewards: -10\n",
      "Episode 51 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 52 played\n",
      "\tSteps: 16\n",
      "\tRewards: -10\n",
      "Episode 53 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 54 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 55 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 56 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 57 played\n",
      "\tSteps: 27\n",
      "\tRewards: -10\n",
      "Episode 58 played\n",
      "\tSteps: 21\n",
      "\tRewards: -10\n",
      "Episode 59 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 60 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "Episode 61 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 62 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 63 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 64 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 65 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:09.962696: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[3,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:10.035692: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[3,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:10.055907: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[3,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 66 played\n",
      "\tSteps: 34\n",
      "\tRewards: -10\n",
      "Episode 67 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 68 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 69 played\n",
      "\tSteps: 48\n",
      "\tRewards: -10\n",
      "Episode 70 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 71 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 72 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 73 played\n",
      "\tSteps: 84\n",
      "\tRewards: -10\n",
      "Episode 74 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 75 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 76 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 77 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 78 played\n",
      "\tSteps: 53\n",
      "\tRewards: -10\n",
      "Episode 79 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 80 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 81 played\n",
      "\tSteps: 11\n",
      "\tRewards: -10\n",
      "Episode 82 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 83 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 84 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 85 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 86 played\n",
      "\tSteps: 17\n",
      "\tRewards: 0\n",
      "Episode 87 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 88 played\n",
      "\tSteps: 13\n",
      "\tRewards: -10\n",
      "Episode 89 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 90 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 91 played\n",
      "\tSteps: 58\n",
      "\tRewards: -10\n",
      "Episode 92 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 93 played\n",
      "\tSteps: 27\n",
      "\tRewards: -10\n",
      "Episode 94 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 95 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 96 played\n",
      "\tSteps: 63\n",
      "\tRewards: -10\n",
      "Episode 97 played\n",
      "\tSteps: 2\n",
      "\tRewards: 0\n",
      "Episode 98 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 99 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 100 played\n",
      "\tSteps: 46\n",
      "\tRewards: -10\n",
      "Episode 101 played\n",
      "\tSteps: 25\n",
      "\tRewards: -10\n",
      "Episode 102 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 103 played\n",
      "\tSteps: 68\n",
      "\tRewards: -10\n",
      "Episode 104 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 105 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 106 played\n",
      "\tSteps: 22\n",
      "\tRewards: -10\n",
      "Episode 107 played\n",
      "\tSteps: 35\n",
      "\tRewards: -10\n",
      "Episode 108 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 109 played\n",
      "\tSteps: 15\n",
      "\tRewards: -10\n",
      "Episode 110 played\n",
      "\tSteps: 15\n",
      "\tRewards: -10\n",
      "Episode 111 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 112 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 113 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 114 played\n",
      "\tSteps: 13\n",
      "\tRewards: -10\n",
      "Episode 115 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 116 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 117 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n",
      "Episode 118 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 119 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 120 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 121 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 122 played\n",
      "\tSteps: 57\n",
      "\tRewards: -10\n",
      "Episode 123 played\n",
      "\tSteps: 8\n",
      "\tRewards: -10\n",
      "Episode 124 played\n",
      "\tSteps: 46\n",
      "\tRewards: -10\n",
      "Episode 125 played\n",
      "\tSteps: 16\n",
      "\tRewards: -10\n",
      "Episode 126 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 127 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 128 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 129 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "Episode 130 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 131 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 132 played\n",
      "\tSteps: 37\n",
      "\tRewards: -10\n",
      "Episode 133 played\n",
      "\tSteps: 45\n",
      "\tRewards: -10\n",
      "Episode 134 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 135 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 136 played\n",
      "\tSteps: 32\n",
      "\tRewards: -10\n",
      "Episode 137 played\n",
      "\tSteps: 7\n",
      "\tRewards: -10\n",
      "Episode 138 played\n",
      "\tSteps: 38\n",
      "\tRewards: -10\n",
      "Episode 139 played\n",
      "\tSteps: 69\n",
      "\tRewards: -10\n",
      "Episode 140 played\n",
      "\tSteps: 16\n",
      "\tRewards: -10\n",
      "Episode 141 played\n",
      "\tSteps: 44\n",
      "\tRewards: 10\n",
      "Episode 142 played\n",
      "\tSteps: 27\n",
      "\tRewards: -10\n",
      "Episode 143 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 144 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 145 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 146 played\n",
      "\tSteps: 21\n",
      "\tRewards: -10\n",
      "Episode 147 played\n",
      "\tSteps: 199\n",
      "\tRewards: 0\n",
      "Episode 148 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 149 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 150 played\n",
      "\tSteps: 34\n",
      "\tRewards: -10\n",
      "Episode 151 played\n",
      "\tSteps: 17\n",
      "\tRewards: -10\n",
      "Episode 152 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 153 played\n",
      "\tSteps: 29\n",
      "\tRewards: -10\n",
      "Episode 154 played\n",
      "\tSteps: 21\n",
      "\tRewards: -10\n",
      "Episode 155 played\n",
      "\tSteps: 43\n",
      "\tRewards: 0\n",
      "Episode 156 played\n",
      "\tSteps: 15\n",
      "\tRewards: -10\n",
      "Episode 157 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "Episode 158 played\n",
      "\tSteps: 45\n",
      "\tRewards: -10\n",
      "Episode 159 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "Episode 160 played\n",
      "\tSteps: 14\n",
      "\tRewards: -10\n",
      "Episode 161 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 162 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "Episode 163 played\n",
      "\tSteps: 36\n",
      "\tRewards: -10\n",
      "Episode 164 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 165 played\n",
      "\tSteps: 44\n",
      "\tRewards: -10\n",
      "Episode 166 played\n",
      "\tSteps: 26\n",
      "\tRewards: -10\n",
      "Episode 167 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 168 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 169 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 170 played\n",
      "\tSteps: 32\n",
      "\tRewards: 0\n",
      "Episode 171 played\n",
      "\tSteps: 69\n",
      "\tRewards: -10\n",
      "Episode 172 played\n",
      "\tSteps: 28\n",
      "\tRewards: -10\n",
      "Episode 173 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "Episode 174 played\n",
      "\tSteps: 58\n",
      "\tRewards: -10\n",
      "Episode 175 played\n",
      "\tSteps: 6\n",
      "\tRewards: -10\n",
      "Episode 176 played\n",
      "\tSteps: 60\n",
      "\tRewards: -10\n",
      "Episode 177 played\n",
      "\tSteps: 3\n",
      "\tRewards: -10\n",
      "Episode 178 played\n",
      "\tSteps: 10\n",
      "\tRewards: 0\n",
      "Episode 179 played\n",
      "\tSteps: 20\n",
      "\tRewards: -10\n",
      "Episode 180 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "Episode 181 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 182 played\n",
      "\tSteps: 8\n",
      "\tRewards: -10\n",
      "Episode 183 played\n",
      "\tSteps: 9\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:10.833038: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[4,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:10.889678: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[4,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:10.959939: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[4,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 184 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 185 played\n",
      "\tSteps: 34\n",
      "\tRewards: -10\n",
      "Episode 186 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "Episode 187 played\n",
      "\tSteps: 39\n",
      "\tRewards: -10\n",
      "Episode 188 played\n",
      "\tSteps: 8\n",
      "\tRewards: -10\n",
      "Episode 189 played\n",
      "\tSteps: 15\n",
      "\tRewards: -10\n",
      "Episode 190 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n",
      "Episode 191 played\n",
      "\tSteps: 15\n",
      "\tRewards: 0\n",
      "Episode 192 played\n",
      "\tSteps: 1\n",
      "\tRewards: 0\n",
      "Episode 193 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "Episode 194 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 195 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 196 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 197 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "Episode 198 played\n",
      "\tSteps: 11\n",
      "\tRewards: -10\n",
      "Episode 199 played\n",
      "\tSteps: 8\n",
      "\tRewards: -10\n",
      "Episode 200 played\n",
      "\tSteps: 32\n",
      "\tRewards: -10\n",
      "Episode 201 played\n",
      "\tSteps: 50\n",
      "\tRewards: -10\n",
      "\tSnaphshot saved (avg. -10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:11.395568: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[32,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:11.473988: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[32,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:11.544997: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[32,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:11.875475: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[29,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:11.941285: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[29,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:11.995191: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[29,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:12.497706: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[31,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:12.568333: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[31,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:12.622838: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[31,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 1\n",
      "\tTraining finished\n",
      "Episode 202 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:13.852569: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[23,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:13.914029: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[23,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:13.966976: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[23,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 4\n",
      "\tTraining finished\n",
      "Episode 203 played\n",
      "\tSteps: 13\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:14.640905: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[26,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:14.696922: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[26,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:14.752795: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[26,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:15.110189: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[30,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:15.167962: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[30,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:15.224421: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[30,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 6\n",
      "\tTraining finished\n",
      "Episode 204 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "\tPriority: 8\n",
      "\tTraining finished\n",
      "Episode 205 played\n",
      "\tSteps: 26\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:15.810251: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[8,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:15.862580: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[8,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:15.931255: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[8,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:16.300764: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[24,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:16.366587: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[24,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:16.431413: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[24,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 9\n",
      "\tTraining finished\n",
      "Episode 206 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "\tPriority: 10\n",
      "\tTraining finished\n",
      "Episode 207 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:17.031889: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[2,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:17.108680: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[2,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:17.133606: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[2,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:17.506589: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[22,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[22,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:17.571246: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[22,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[22,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:17.625822: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[22,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[22,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 13\n",
      "\tTraining finished\n",
      "Episode 208 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "\tPriority: 14\n",
      "\tTraining finished\n",
      "Episode 209 played\n",
      "\tSteps: 22\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:18.226196: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[5,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:18.267231: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[5,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:18.326679: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[5,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 16\n",
      "\tTraining finished\n",
      "Episode 210 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "\tPriority: 17\n",
      "\tTraining finished\n",
      "Episode 211 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:19.138344: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[11,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:19.180292: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[11,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:19.240183: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[11,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[11,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:19.624106: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[25,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[25,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:19.684301: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[25,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[25,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:19.737440: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[25,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[25,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 17\n",
      "\tTraining finished\n",
      "Episode 212 played\n",
      "\tSteps: 32\n",
      "\tRewards: -10\n",
      "\tPriority: 18\n",
      "\tTraining finished\n",
      "Episode 213 played\n",
      "\tSteps: 2\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:20.329113: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[28,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:20.410301: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[28,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:20.482160: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[28,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:20.870815: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[20,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:20.940187: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[20,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:21.010366: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[20,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPriority: 23\n",
      "\tTraining finished\n",
      "Episode 214 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "\tPriority: 16\n",
      "\tTraining finished\n",
      "Episode 215 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "\tPriority: 16\n",
      "\tTraining finished\n",
      "Episode 216 played\n",
      "\tSteps: 19\n",
      "\tRewards: -10\n",
      "\tPriority: 16\n",
      "\tTraining finished\n",
      "Episode 217 played\n",
      "\tSteps: 40\n",
      "\tRewards: -10\n",
      "\tPriority: 17\n",
      "\tTraining finished\n",
      "Episode 218 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "\tPriority: 20\n",
      "\tTraining finished\n",
      "Episode 219 played\n",
      "\tSteps: 32\n",
      "\tRewards: -10\n",
      "\tPriority: 21\n",
      "\tTraining finished\n",
      "Episode 220 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "\tPriority: 23\n",
      "\tTraining finished\n",
      "Episode 221 played\n",
      "\tSteps: 1\n",
      "\tRewards: -10\n",
      "\tPriority: 24\n",
      "\tTraining finished\n",
      "Episode 222 played\n",
      "\tSteps: 27\n",
      "\tRewards: -10\n",
      "\tPriority: 26\n",
      "\tTraining finished\n",
      "Episode 223 played\n",
      "\tSteps: 12\n",
      "\tRewards: -10\n",
      "\tPriority: 28\n",
      "\tTraining finished\n",
      "Episode 224 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "\tPriority: 30\n",
      "\tTraining finished\n",
      "Episode 225 played\n",
      "\tSteps: 5\n",
      "\tRewards: -10\n",
      "\tPriority: 30\n",
      "\tTraining finished\n",
      "Episode 226 played\n",
      "\tSteps: 30\n",
      "\tRewards: -10\n",
      "\tPriority: 31\n",
      "\tTraining finished\n",
      "Episode 227 played\n",
      "\tSteps: 10\n",
      "\tRewards: -10\n",
      "\tPriority: 31\n",
      "\tTraining finished\n",
      "Episode 228 played\n",
      "\tSteps: 29\n",
      "\tRewards: -10\n",
      "\tPriority: 32\n",
      "\tTraining finished\n",
      "Episode 229 played\n",
      "\tSteps: 0\n",
      "\tRewards: -10\n",
      "\tPriority: 33\n",
      "\tTraining finished\n",
      "Episode 230 played\n",
      "\tSteps: 17\n",
      "\tRewards: -10\n",
      "\tPriority: 33\n",
      "\tTraining finished\n",
      "Episode 231 played\n",
      "\tSteps: 4\n",
      "\tRewards: -10\n",
      "\tPriority: 34\n",
      "\tTraining finished\n",
      "Episode 232 played\n",
      "\tSteps: 17\n",
      "\tRewards: -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 20:46:24.473316: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.13 = (f32[21,32,15,15]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,32,15,15]{3,2,1,0} %bitcast.289, f32[32,32,5,5]{3,2,1,0} %bitcast.296, f32[32]{0} %bitcast.298), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:24.526984: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.14 = (f32[21,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,32,7,7]{3,2,1,0} %bitcast.305, f32[64,32,3,3]{3,2,1,0} %bitcast.312, f32[64]{0} %bitcast.314), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:24.575980: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{} for conv %cudnn-conv-bias-activation.15 = (f32[21,64,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,64,7,7]{3,2,1,0} %bitcast.319, f32[64,64,3,3]{3,2,1,0} %bitcast.326, f32[64]{0} %bitcast.328), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_3_1/convolution\" source_file=\"/home/rs/PycharmProjects/snake-multi/.venv/lib64/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-09-03 20:46:24.781923: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : INTERNAL: ptxas exited with non-zero error code 2, output: \n",
      "2025-09-03 20:46:24.781949: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: ptxas exited with non-zero error code 2, output: \n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulation = Simulation(calculate_score)\n",
    "rewards = []\n",
    "steps = []\n",
    "replay_buffer.clear()\n",
    "\n",
    "best_model_window = 7\n",
    "best_model_rewards = float(\"-inf\")\n",
    "\n",
    "n_episodes = 100_000\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    simulation.reset(make_simple_board(np.array([15, 15])), snake_count=1, food_count=1)\n",
    "\n",
    "    rewards.append(0)\n",
    "\n",
    "    states = [simulation.get_snake_view(i, view_type, view_range) for i in range(simulation.n_snakes)]\n",
    "    possible_moves = [simulation.get_legal_moves(i) for i in range(simulation.n_snakes)]\n",
    "    snakes_alive = simulation.snakes_alive\n",
    "    \n",
    "    epsilon = max(1 - (episode / (n_episodes * 0.8)), 0.005)\n",
    "    priority_buffer_split = min(episode / (n_episodes * 0.8) * 0.2, 0.2)\n",
    "\n",
    "    for step in range(200):\n",
    "        #discount_factor = 0.95 * (episode / n_episodes)\n",
    "        \n",
    "        states, possible_moves, snakes_alive, scores, running = play_one_step(simulation, states, possible_moves, snakes_alive, epsilon)\n",
    "\n",
    "        rewards[-1] += sum(scores)\n",
    "\n",
    "        if not running:\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "\n",
    "    logging.info(f\"Episode {episode} played\")\n",
    "    logging.info(f\"\\tSteps: {step}\")\n",
    "    logging.info(f\"\\tRewards: {rewards[-1]}\")\n",
    "\n",
    "    if episode > 200:\n",
    "        curr_model_rewards = sum(rewards[-best_model_window:])\n",
    "        if curr_model_rewards > best_model_rewards:\n",
    "            avg_rewards = curr_model_rewards / best_model_window\n",
    "            best_model_rewards = curr_model_rewards\n",
    "            logging.info(f\"\\tSnaphshot saved (avg. {avg_rewards})\")\n",
    "            \n",
    "            if model_name:\n",
    "                online_model.save(f\"models/{model_name}_{round(avg_rewards)}_snapshot.keras\")\n",
    "\n",
    "        training_step(priority_buffer_split)\n",
    "        logging.info(\"\\tTraining finished\")\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            target_model.set_weights(online_model.get_weights())\n",
    "            logging.info(\"\\tTarget model updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5844b-e610-4de5-a7a1-44aaebfb35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(steps, label=\"steps\")\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "sns.lineplot(np.convolve(rewards, [1 for _ in range(10)]))\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5368a-fc9c-4af1-bd45-ba327d6a8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "sns.lineplot(np.convolve(losses, [1 for _ in range(10)]), ax=ax)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2973a-9bca-43f0-afd9-c19ac610e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "sns.lineplot(np.cumsum(rewards), label=\"rewards\", ax=ax)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0760a4-0202-4577-9306-8d4f2c5bf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_model.save(f\"models/{model_name}.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
